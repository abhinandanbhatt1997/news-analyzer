(myenv) abhinandan@Abhinandan:~/news-analyzer$ cat README.md
#These were the initial prompts before implementation.

#Prompt_Gemini
You are a news analyst.

Analyze the following news article strictly based on its content.
Do NOT add external facts or assumptions.

Return your response in valid JSON with the following schema:

{
  "gist": "1–2 sentence factual summary of the article",
  "sentiment": "positive | negative | neutral",
  "tone": "analytical | urgent | critical | balanced | satirical | informational",
  "justification": "Brief explanation (1–2 sentences) quoting or referring to phrases from the article"
}

Guidelines:
- Sentiment reflects overall emotional polarity of the news.
- Tone reflects the writing style, not your opinion.
- If the article is factual reporting without strong language, use sentiment = neutral and tone = informational or analytical.
- Do not hallucinate facts not present in the article.
- If the article content is insufficient, return sentiment = neutral and explain why in justification.

Article:
<<<
{ARTICLE_TEXT}
>>>

#Prompt_Mistral :

You are a critical reviewer.

You are given:
1. A news article
2. An analysis generated by another LLM

Your task:
- Check whether the gist, sentiment, and tone accurately reflect the article.
- Identify any factual mismatches, exaggerations, or misclassifications.

Return your response in valid JSON with the following schema:

{
  "verdict": "correct | partially_correct | incorrect",
  "issues": "Brief explanation of any problems found. If none, say 'No issues found.'"
}

Rules:
- Base your judgment strictly on the article text.
- Do NOT rewrite the analysis.
- Be concise and critical, not polite.

Article:
<<<
{ARTICLE_TEXT}
>>>

Analysis to validate:
<<<
{LLM1_OUTPUT_JSON}
>>>


## Task 1: Fetch News Articles

I used NewsAPI as the primary source due to its reliability and simple schema.
I added retry logic and explicit normalization to ensure downstream LLM prompts
receive clean, predictable inputs. Articles with missing or short content were
filtered to reduce hallucinations during analysis.

Phase 1: Setup & Environment

Created Python virtual environment: myenv.

Installed required packages: requests, python-dotenv, google-genai (for Gemini LLM), etc.

Created directory structure:

news-analyzer/
├─ src/
│  ├─ news_fetcher.py
│  ├─ llm_analyzer.py
│  └─ __init__.py
├─ tests/
├─ .env
└─ DEVELOPMENT_PROCESS.md

Phase 2: API Key Management

Gathered API keys for:

News API

Gemini (Google)

OpenRouter / Mistral (if needed for future extensions)

Stored them securely in .env file.

Loaded keys using dotenv in Python code.

Phase 3: News Fetching (news_fetcher.py)

Implemented fetch_news() function:

Fetches latest articles via News API.

Handles missing API key errors.

Returns articles as Python dictionaries.

Tested fetching single and multiple articles.

Phase 4: LLM Analysis (llm_analyzer.py)

Implemented analyze_article(article: dict):

Sends the news article to Gemini LLM.

Receives text analysis with summary, sentiment, key entities, and reasoning.

Handles API errors and wraps them in LLMAnalysisError.

Resolved Gemini model version issues by listing available models:

Selected models/gemini-1.5-flash-latest (working model for generate_content).

Tested with live articles; verified output.

Phase 5: Validation & Error Handling

Added:

Exception handling for API errors.

Validation for missing fields (to be added after JSON parsing).

Robustness for future LLM changes or key rotations.

Phase 6: Next Steps (Planned)

Parse LLM output into structured JSON for downstream tasks.

Implement storage or dashboard integration for analyzed results.

Optionally expand to other LLMs like Mistral or OpenRouter.

Add unit tests for all modules.
